{"cells":[{"cell_type":"markdown","metadata":{"id":"HvmYwZx9W_kF"},"source":["### Defining imports"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-05-05T02:14:54.308640Z","iopub.status.busy":"2024-05-05T02:14:54.307582Z","iopub.status.idle":"2024-05-05T02:14:56.854411Z","shell.execute_reply":"2024-05-05T02:14:56.853374Z","shell.execute_reply.started":"2024-05-05T02:14:54.308604Z"},"id":"drsn5ZbYW_kI","trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import pickle\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler, normalize\n","from sklearn.decomposition import PCA\n","from torch.optim.lr_scheduler import ReduceLROnPlateau\n","\n","seed=42\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed(seed)\n","torch.backends.cudnn.benchmark = False"]},{"cell_type":"markdown","metadata":{"id":"R-7qGCB9W_kK"},"source":["### Loading the dataset\n","\n","After dataset loading, we remove duplicated or NaN rows.\n","We expect to get the same NaN and duplicates results as in ML notebook, so we skip this print and we pass to test, validation and training split. We also do a winsorization to handle outliers."]},{"cell_type":"code","execution_count":2,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-05-05T02:14:56.856531Z","iopub.status.busy":"2024-05-05T02:14:56.856098Z","iopub.status.idle":"2024-05-05T02:15:20.566753Z","shell.execute_reply":"2024-05-05T02:15:20.565764Z","shell.execute_reply.started":"2024-05-05T02:14:56.856503Z"},"id":"1lXTfn5uW_kK","outputId":"da1d5409-4342-4f8d-e6a2-a02d695040ef","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["----Training Set----\n","X_train Shape: (182158, 90)\n","y_train Shape: (182158,)\n","\n","----Validation Set----\n","X_val Shape: (32146, 90)\n","y_val Shape: (32146,)\n","\n","----Test Set----\n","X_test Shape: (37819, 90)\n","y_test Shape: (37819,)\n"]}],"source":["df = pd.read_csv(\"../datasets/train.csv\")\n","\n","df = df.drop_duplicates()\n","\n","df = df.dropna()\n","\n","X = df.drop('Year', axis=1)\n","y = df['Year']\n","\n","def winsorize_outliers(df, column, lower_limit, upper_limit):\n","    df[column] = np.where(df[column] < lower_limit, lower_limit, df[column])\n","    df[column] = np.where(df[column] > upper_limit, upper_limit, df[column])\n","    return df\n","\n","lower_limit = X.quantile(0.05, axis=0)\n","upper_limit = X.quantile(0.95, axis=0)\n","\n","for col in X.columns:\n","    X = winsorize_outliers(X.copy(), col, lower_limit[col], upper_limit[col])\n","\n","X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.15, random_state=seed)\n","\n","X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.15, random_state=seed)\n","\n","print(\"----Training Set----\")\n","print(\"X_train Shape:\", X_train.shape)\n","print(\"y_train Shape:\", y_train.shape)\n","\n","print(\"\\n----Validation Set----\")\n","print(\"X_val Shape:\", X_val.shape)\n","print(\"y_val Shape:\", y_val.shape)\n","\n","print(\"\\n----Test Set----\")\n","print(\"X_test Shape:\", X_test.shape)\n","print(\"y_test Shape:\", y_test.shape)"]},{"cell_type":"markdown","metadata":{"id":"ml23pLWaW_kM"},"source":["### Standard Scaling\n","A Standard scaler is fitted and saved for later usage. The MinMaxScaler, L1/L2 normalization and PCA were also tried but gave worse results on the network."]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-05-05T02:15:20.568332Z","iopub.status.busy":"2024-05-05T02:15:20.568039Z","iopub.status.idle":"2024-05-05T02:15:20.919291Z","shell.execute_reply":"2024-05-05T02:15:20.918270Z","shell.execute_reply.started":"2024-05-05T02:15:20.568307Z"},"id":"lTSttBhGW_kM","trusted":true},"outputs":[],"source":["scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_val = scaler.transform(X_val)\n","X_test = scaler.transform(X_test)\n","\n","#scaler = MinMaxScaler()\n","#X_train = scaler.fit_transform(X_train)\n","#X_val = scaler.transform(X_val)\n","#X_test = scaler.transform(X_test)\n","\n","#normalization l1\n","#X_train = normalize(X_train, norm=\"l1\")\n","#X_val = normalize(X_val, norm=\"l1\")\n","#X_test = normalize(X_test, norm=\"l1\")\n","\n","#normalization l2\n","#X_train = normalize(X_train, norm=\"l2\")\n","#X_val = normalize(X_val, norm=\"l2\")\n","#X_test = normalize(X_test, norm=\"l2\")\n","\n","#pca\n","#pca = PCA(0.99)\n","#X_train = pca.fit_transform(X_train)\n","#X_val = pca.transform(X_val)\n","#X_test = pca.transform(X_test)\n","\n","X_train = pd.DataFrame(X_train)\n","X_val = pd.DataFrame(X_val)\n","X_test = pd.DataFrame(X_test)\n","\n","file = open(\"scaler.save\",\"wb\")\n","pickle.dump(scaler, file)\n","file.close()\n","\n","#file = open(\"pca.save\",\"wb\")\n","#pickle.dump(pca, file)\n","#file.close()"]},{"cell_type":"markdown","metadata":{"id":"EDHUYgvJW_kN"},"source":["### Custom Dataset\n","The dataset is converted in Torch tensors and a CustomDataset class is created and later used to convert the three dataset we obtained before."]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-05-05T02:15:20.921873Z","iopub.status.busy":"2024-05-05T02:15:20.921567Z","iopub.status.idle":"2024-05-05T02:15:20.960352Z","shell.execute_reply":"2024-05-05T02:15:20.959429Z","shell.execute_reply.started":"2024-05-05T02:15:20.921848Z"},"id":"H2OjPfuuW_kN","trusted":true},"outputs":[],"source":["class CustomDataset(torch.utils.data.Dataset):\n","    def __init__(self, X, y):\n","        self.X = torch.FloatTensor(X.values)\n","        self.y = torch.FloatTensor(y.values)\n","\n","    def __len__(self):\n","        return len(self.X)\n","\n","    def __getitem__(self, idx):\n","        return self.X[idx], self.y[idx]\n","\n","train_dataset = CustomDataset(X_train, y_train)\n","val_dataset = CustomDataset(X_val, y_val)\n","test_dataset = CustomDataset(X_test, y_test)"]},{"cell_type":"markdown","metadata":{"id":"q3dnOpqhW_kO"},"source":["### FeedForward Neural Network architecture\n","After several tries we settled on this architecture as the one with the best performances.\n","This network use linear layers and the RELU activation function."]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-05-05T02:15:20.962647Z","iopub.status.busy":"2024-05-05T02:15:20.961631Z","iopub.status.idle":"2024-05-05T02:15:20.971524Z","shell.execute_reply":"2024-05-05T02:15:20.970568Z","shell.execute_reply.started":"2024-05-05T02:15:20.962617Z"},"id":"Xn4oE_GRW_kO","trusted":true},"outputs":[],"source":["class FeedForward(nn.Module):\n","    def __init__(self, input_size):\n","        super(FeedForward, self).__init__()\n","        self.fc1 = nn.Linear(input_size, 512)\n","        self.fc2 = nn.Linear(512, 256)\n","        self.fc3 = nn.Linear(256, 128)\n","        self.fc4 = nn.Linear(128, 64)\n","        self.fc5 = nn.Linear(64, 32)\n","        self.fc6 = nn.Linear(32, 1)\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, x):\n","        x = self.fc1(x)\n","        x = self.relu(x)\n","        x = self.fc2(x)\n","        x = self.relu(x)\n","        x = self.fc3(x)\n","        x = self.relu(x)\n","        x = self.fc4(x)\n","        x = self.relu(x)\n","        x = self.fc5(x)\n","        x = self.relu(x)\n","        x = self.fc6(x)\n","        return x"]},{"cell_type":"markdown","metadata":{"id":"iPwDpYWSW_kO"},"source":["### Network training parameters\n","Here are all the settings we applied to our NN training:\n","* MSE is picked as loss function\n","* The batch size is set at 1024 items\n","* The chosen optimizer is Adam\n","\n","We let the training run for 100 epochs, checking the loss at every epoch and reducing the learning rate by 10% every time the loss doesn't improve for 5 epochs in a row."]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-05-05T02:15:20.972880Z","iopub.status.busy":"2024-05-05T02:15:20.972591Z","iopub.status.idle":"2024-05-05T02:15:22.418128Z","shell.execute_reply":"2024-05-05T02:15:22.417287Z","shell.execute_reply.started":"2024-05-05T02:15:20.972857Z"},"id":"CgWq8rUaW_kP","trusted":true},"outputs":[],"source":["input_size = X_train.shape[1]\n","model = FeedForward(input_size)\n","\n","criterion = nn.MSELoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n","scheduler = ReduceLROnPlateau(optimizer, factor=0.1, patience=5)\n","\n","num_epochs = 100\n","batch_size = 1024\n","train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n","test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"]},{"cell_type":"markdown","metadata":{"id":"MnT1KXZIW_kP"},"source":["### Neural Network training\n","During the training we also restore the model to the epoch in which it had the best validation loss, before saving it in `best_model.pth`"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-05-05T02:15:22.419643Z","iopub.status.busy":"2024-05-05T02:15:22.419218Z","iopub.status.idle":"2024-05-05T02:21:47.517951Z","shell.execute_reply":"2024-05-05T02:21:47.517024Z","shell.execute_reply.started":"2024-05-05T02:15:22.419616Z"},"id":"fsMG0VD8W_kQ","outputId":"1090bf2f-5169-4ab3-f773-e946d4e32efc","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch [1/100], Training Loss: 344819.5424\n","Validation Loss: 34235.4482\n","Epoch [2/100], Training Loss: 24627.4769\n","Validation Loss: 14768.7085\n","Epoch [3/100], Training Loss: 7788.0141\n","Validation Loss: 2760.8226\n","Epoch [4/100], Training Loss: 1333.9090\n","Validation Loss: 662.6027\n","Epoch [5/100], Training Loss: 371.7464\n","Validation Loss: 250.7145\n","Epoch [6/100], Training Loss: 200.3449\n","Validation Loss: 205.3655\n","Epoch [7/100], Training Loss: 167.1373\n","Validation Loss: 167.0869\n","Epoch [8/100], Training Loss: 170.7569\n","Validation Loss: 223.1501\n","Epoch [9/100], Training Loss: 255.2103\n","Validation Loss: 195.7880\n","Epoch [10/100], Training Loss: 201.2988\n","Validation Loss: 160.9152\n","Epoch [11/100], Training Loss: 215.5266\n","Validation Loss: 143.1721\n","Epoch [12/100], Training Loss: 187.7732\n","Validation Loss: 149.1644\n","Epoch [13/100], Training Loss: 234.8771\n","Validation Loss: 300.2647\n","Epoch [14/100], Training Loss: 288.9444\n","Validation Loss: 213.8176\n","Epoch [15/100], Training Loss: 191.9556\n","Validation Loss: 240.9037\n","Epoch [16/100], Training Loss: 412.6483\n","Validation Loss: 1789.7747\n","Epoch [17/100], Training Loss: 625.1183\n","Validation Loss: 1049.8570\n","Epoch [18/100], Training Loss: 111.7969\n","Validation Loss: 83.8240\n","Epoch [19/100], Training Loss: 77.4809\n","Validation Loss: 84.3277\n","Epoch [20/100], Training Loss: 76.7184\n","Validation Loss: 81.5123\n","Epoch [21/100], Training Loss: 76.1393\n","Validation Loss: 81.7775\n","Epoch [22/100], Training Loss: 76.2437\n","Validation Loss: 81.5006\n","Epoch [23/100], Training Loss: 75.9170\n","Validation Loss: 82.7199\n","Epoch [24/100], Training Loss: 76.4611\n","Validation Loss: 83.1715\n","Epoch [25/100], Training Loss: 75.9318\n","Validation Loss: 82.0231\n","Epoch [26/100], Training Loss: 75.8569\n","Validation Loss: 81.9780\n","Epoch [27/100], Training Loss: 76.7614\n","Validation Loss: 82.0511\n","Epoch [28/100], Training Loss: 76.1484\n","Validation Loss: 81.5736\n","Epoch [29/100], Training Loss: 72.2882\n","Validation Loss: 78.6043\n","Epoch [30/100], Training Loss: 72.1747\n","Validation Loss: 78.4329\n","Epoch [31/100], Training Loss: 72.1963\n","Validation Loss: 78.7711\n","Epoch [32/100], Training Loss: 72.1869\n","Validation Loss: 78.3492\n","Epoch [33/100], Training Loss: 72.1948\n","Validation Loss: 78.6099\n","Epoch [34/100], Training Loss: 72.2589\n","Validation Loss: 78.4754\n","Epoch [35/100], Training Loss: 72.3139\n","Validation Loss: 78.7733\n","Epoch [36/100], Training Loss: 72.3016\n","Validation Loss: 78.5073\n","Epoch [37/100], Training Loss: 72.2994\n","Validation Loss: 78.7639\n","Epoch [38/100], Training Loss: 72.3484\n","Validation Loss: 78.5930\n","Epoch [39/100], Training Loss: 71.6325\n","Validation Loss: 77.9420\n","Epoch [40/100], Training Loss: 71.5502\n","Validation Loss: 77.8825\n","Epoch [41/100], Training Loss: 71.5529\n","Validation Loss: 77.8624\n","Epoch [42/100], Training Loss: 71.5595\n","Validation Loss: 78.0334\n","Epoch [43/100], Training Loss: 71.5691\n","Validation Loss: 77.9750\n","Epoch [44/100], Training Loss: 71.5548\n","Validation Loss: 77.9746\n","Epoch [45/100], Training Loss: 71.5478\n","Validation Loss: 77.9716\n","Epoch [46/100], Training Loss: 71.5583\n","Validation Loss: 77.8831\n","Epoch [47/100], Training Loss: 71.5420\n","Validation Loss: 78.0146\n","Epoch [48/100], Training Loss: 71.4570\n","Validation Loss: 77.8469\n","Epoch [49/100], Training Loss: 71.4181\n","Validation Loss: 77.8309\n","Epoch [50/100], Training Loss: 71.4138\n","Validation Loss: 77.8326\n","Epoch [51/100], Training Loss: 71.4144\n","Validation Loss: 77.8214\n","Epoch [52/100], Training Loss: 71.4115\n","Validation Loss: 77.8191\n","Epoch [53/100], Training Loss: 71.4155\n","Validation Loss: 77.8518\n","Epoch [54/100], Training Loss: 71.4111\n","Validation Loss: 77.8505\n","Epoch [55/100], Training Loss: 71.4081\n","Validation Loss: 77.8594\n","Epoch [56/100], Training Loss: 71.4151\n","Validation Loss: 77.8423\n","Epoch [57/100], Training Loss: 71.4142\n","Validation Loss: 77.8255\n","Epoch [58/100], Training Loss: 71.3877\n","Validation Loss: 77.8245\n","Epoch [59/100], Training Loss: 71.3842\n","Validation Loss: 77.8283\n","Epoch [60/100], Training Loss: 71.3835\n","Validation Loss: 77.8302\n","Epoch [61/100], Training Loss: 71.3831\n","Validation Loss: 77.8298\n","Epoch [62/100], Training Loss: 71.3829\n","Validation Loss: 77.8289\n","Epoch [63/100], Training Loss: 71.3836\n","Validation Loss: 77.8303\n","Epoch [64/100], Training Loss: 71.3798\n","Validation Loss: 77.8303\n","Epoch [65/100], Training Loss: 71.3798\n","Validation Loss: 77.8302\n","Epoch [66/100], Training Loss: 71.3797\n","Validation Loss: 77.8300\n","Epoch [67/100], Training Loss: 71.3797\n","Validation Loss: 77.8300\n","Epoch [68/100], Training Loss: 71.3796\n","Validation Loss: 77.8298\n","Epoch [69/100], Training Loss: 71.3795\n","Validation Loss: 77.8297\n","Epoch [70/100], Training Loss: 71.3795\n","Validation Loss: 77.8298\n","Epoch [71/100], Training Loss: 71.3795\n","Validation Loss: 77.8298\n","Epoch [72/100], Training Loss: 71.3795\n","Validation Loss: 77.8296\n","Epoch [73/100], Training Loss: 71.3794\n","Validation Loss: 77.8297\n","Epoch [74/100], Training Loss: 71.3793\n","Validation Loss: 77.8296\n","Epoch [75/100], Training Loss: 71.3793\n","Validation Loss: 77.8295\n","Epoch [76/100], Training Loss: 71.3793\n","Validation Loss: 77.8297\n","Epoch [77/100], Training Loss: 71.3793\n","Validation Loss: 77.8296\n","Epoch [78/100], Training Loss: 71.3793\n","Validation Loss: 77.8295\n","Epoch [79/100], Training Loss: 71.3793\n","Validation Loss: 77.8297\n","Epoch [80/100], Training Loss: 71.3793\n","Validation Loss: 77.8295\n","Epoch [81/100], Training Loss: 71.3792\n","Validation Loss: 77.8294\n","Epoch [82/100], Training Loss: 71.3792\n","Validation Loss: 77.8295\n","Epoch [83/100], Training Loss: 71.3793\n","Validation Loss: 77.8296\n","Epoch [84/100], Training Loss: 71.3792\n","Validation Loss: 77.8294\n","Epoch [85/100], Training Loss: 71.3792\n","Validation Loss: 77.8295\n","Epoch [86/100], Training Loss: 71.3792\n","Validation Loss: 77.8295\n","Epoch [87/100], Training Loss: 71.3791\n","Validation Loss: 77.8295\n","Epoch [88/100], Training Loss: 71.3791\n","Validation Loss: 77.8294\n","Epoch [89/100], Training Loss: 71.3793\n","Validation Loss: 77.8295\n","Epoch [90/100], Training Loss: 71.3791\n","Validation Loss: 77.8294\n","Epoch [91/100], Training Loss: 71.3791\n","Validation Loss: 77.8295\n","Epoch [92/100], Training Loss: 71.3791\n","Validation Loss: 77.8295\n","Epoch [93/100], Training Loss: 71.3791\n","Validation Loss: 77.8295\n","Epoch [94/100], Training Loss: 71.3790\n","Validation Loss: 77.8295\n","Epoch [95/100], Training Loss: 71.3790\n","Validation Loss: 77.8294\n","Epoch [96/100], Training Loss: 71.3790\n","Validation Loss: 77.8295\n","Epoch [97/100], Training Loss: 71.3790\n","Validation Loss: 77.8295\n","Epoch [98/100], Training Loss: 71.3790\n","Validation Loss: 77.8294\n","Epoch [99/100], Training Loss: 71.3790\n","Validation Loss: 77.8293\n","Epoch [100/100], Training Loss: 71.3789\n","Validation Loss: 77.8292\n"]}],"source":["best_val_loss = float('inf')\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    running_loss = 0.0\n","    for inputs, labels in train_loader:\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels.view(-1, 1))\n","        loss.backward()\n","        optimizer.step()\n","        running_loss += loss.item() * inputs.size(0)\n","    epoch_loss = running_loss / len(train_dataset)\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {epoch_loss:.4f}\")\n","\n","    model.eval()\n","    val_loss = 0.0\n","    with torch.no_grad():\n","        for val_inputs, val_labels in val_loader:\n","            val_outputs = model(val_inputs)\n","            val_loss += criterion(val_outputs, val_labels.view(-1, 1)).item() * val_inputs.size(0)\n","    val_loss /= len(val_dataset)\n","    print(f\"Validation Loss: {val_loss:.4f}\")\n","    scheduler.step(val_loss)\n","\n","    if val_loss < best_val_loss:\n","        best_val_loss = val_loss\n","        best_model_state = model.state_dict()\n","        torch.save(best_model_state, 'best_model.pth')"]},{"cell_type":"markdown","metadata":{"id":"HJnY-W9aW_kQ"},"source":["### Network testing\n","Here are the metrics from `best_model.pth` on the test set"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-05-05T02:21:47.519627Z","iopub.status.busy":"2024-05-05T02:21:47.519248Z","iopub.status.idle":"2024-05-05T02:21:47.954860Z","shell.execute_reply":"2024-05-05T02:21:47.953826Z","shell.execute_reply.started":"2024-05-05T02:21:47.519590Z"},"id":"1GpeAItNW_kQ","outputId":"cb0290a0-208c-4ef9-9bbf-0675383bc66b","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Test Loss: 76.0278\n","Test R2 Score: 0.2955, Test MSE: 76.0278, Test MAPE: 0.0032, Test MAE: 6.3458\n"]}],"source":["input_size = X_train.shape[1]\n","clf = FeedForward(input_size)\n","best_model_state = torch.load('best_model.pth')\n","clf.load_state_dict(best_model_state)\n","\n","clf.eval()\n","test_loss = 0.0\n","predictions = []\n","true_labels = []\n","\n","with torch.no_grad():\n","    for test_inputs, test_labels in test_loader:\n","        test_outputs = model(test_inputs)\n","        test_loss += criterion(test_outputs, test_labels.view(-1, 1)).item() * test_inputs.size(0)\n","        predictions.extend(test_outputs.numpy())\n","        true_labels.extend(test_labels.numpy())\n","\n","test_loss /= len(test_dataset)\n","print(f\"Test Loss: {test_loss:.4f}\")\n","r2_test = r2_score(true_labels, predictions)\n","mse_test = mean_squared_error(true_labels, predictions)\n","mape_test = mean_absolute_percentage_error(true_labels, predictions)\n","mae_test = mean_absolute_error(true_labels, predictions)\n","print(f\"Test R2 Score: {r2_test:.4f}, Test MSE: {mse_test:.4f}, Test MAPE: {mape_test:.4f}, Test MAE: {mae_test:.4f}\")"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4940646,"sourceId":8318142,"sourceType":"datasetVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":4}
